# User Journeys

## Journey 1: Alex Chen - From AI Podcast Creator to Content Empire Builder

Alex is a 34-year-old educational entrepreneur who discovered he could create AI-generated podcasts on complex topics in minutes. The problem? He has 50 podcast episodes sitting on his hard drive because transforming them into blog posts, social media content, and newsletter segments takes him 3-4 hours per episode - time he doesn't have. His audience keeps asking "where's the blog version?" but he's stuck in creation limbo.

Late one Tuesday, after another week of zero content published despite having 4 new podcast episodes ready, Alex searches "AI podcast to blog post service" and finds jabur. The promise of 24-48 hour turnaround with human curation catches his attention - he's tried pure AI tools and the quality was terrible. He uploads his first 45-minute podcast on "Introduction to Quantum Computing" and selects 3 output types: Executive Summary, Blog Post, and Social Media Pack.

36 hours later, Alex receives a notification. The Blog Post is... actually good. Really good. Better than he could have written himself. The creator caught nuances from the podcast, added relevant examples, and structured it perfectly for SEO. The Social Media Pack has 10 ready-to-post pieces that capture the essence without dumbing it down. He publishes immediately.

Three months later, Alex has a system: Record podcast Monday, upload to jabur Tuesday, publish across all channels Thursday-Friday. His audience has tripled, his email list is growing 15% monthly, and he's spending his time creating new content instead of reformatting old content. He's upgraded to the rush pricing tier because the ROI is obvious - every $50 he spends on jabur content generates $500+ in course sales.

## Journey 2: Maria Gonzalez - From Gig Platform Burnout to Sustainable Income

Maria is a 42-year-old former magazine editor who left her job to freelance, hoping for flexibility and fair compensation. Instead, she's stuck on gig platforms where she bids against hundreds of writers, clients ghost her after free "test projects," and she never knows if next week will have work. She's talented but exhausted by the constant hustle and low pay.

A writer friend mentions jabur: "It's different - you don't bid, you just claim tasks. The pay is transparent, and there's an actual advancement system." Maria is skeptical but desperate. She applies, submits her portfolio and a sample task, and gets accepted as a Probationary creator. Her first task appears: Create an Executive Summary from a 30-minute podcast about sustainable gardening. Task value: $15. Time estimate: 45-60 minutes.

Maria completes her first task in 50 minutes. The audio player with synchronized transcript makes it easy - she can speed through sections, mark key points, and the editor auto-saves her work. She submits it. 18 hours later: "Approved - Score 4.3/5.0." The $15 hits her pending earnings, and she sees "Progress: 1/20 approvals to Junior (rate: 0.9x)." Two things hit her: the feedback is actually helpful (not vague), and there's a clear path forward.

Six months later, Maria is a Mid-Level creator earning $800-1,200/week working 25-30 hours. She knows exactly when she'll get paid (every Friday), she can see her tier progress (15/30 approvals to Senior), and she's developed a specialty in technical content that pays better. For the first time in 3 years, she's not anxious about money. She tells her friend: "This is the first platform that treats me like a professional, not a commodity."

## Journey 3: James Park - From QA Chaos to Quality at Scale

James is a 38-year-old former senior editor at a publishing house who joined jabur as the first QA Editor when they had 5 creators. Now they have 40 creators submitting 200+ pieces per week, and he's drowning. His inbox is chaos, he's using Google Sheets to track submissions, and he can't remember which creator needs what feedback. Quality is slipping because he's rushing through reviews just to keep up.

The platform team rolls out the new QA dashboard. James is skeptical - he's seen "tools" before that just add more clicks. But he opens it Monday morning: a clean review queue sorted by deadline, each submission showing the rubric template, the original audio with synchronized transcript, and the creator's submission side-by-side. He clicks into his first review - a Blog Post about cryptocurrency regulation.

James realizes he can listen to the audio at 1.5x speed while reading the creator's output, mark specific sections for inline comments, and fill out the rubric scoring in real-time. What used to take 25 minutes now takes 12. The rubric forces him to be consistent - no more vague "needs improvement" feedback. He scores it: Accuracy 5/5, Completeness 4/5, Clarity 5/5, Actionability 4/5, Formatting 5/5, Originality 5/5. Total: 4.7/5 - Approved. The creator gets clear feedback on the completeness gap with specific examples.

Three months later, James is processing 250 reviews per week comfortably. His average review time is down to 10 minutes, quality scores have improved (first-pass rate up from 62% to 74%), and creators are advancing faster because feedback is actionable. He's hired a second QA editor and trained them in 2 days using the same rubric system. Platform leadership asks him: "How do you maintain quality at this scale?" His answer: "The tools do half the work - I just make the judgment calls."

## Journey 4: Sarah Kim - From Firefighter to Strategic Operator

Sarah is a 31-year-old operations manager who thought she was joining a marketplace platform. Instead, she's become a full-time firefighter: clients complaining about quality, creators disputing scores, payment issues every Friday, and she has zero visibility into what actually happened. Every dispute requires her to dig through Slack messages, email threads, and bug developers for database queries. She's spending 30 hours/week on disputes that should take 10.

The engineering team finally ships the Admin Dashboard. Sarah opens it with low expectations. She sees her first dispute: "Client rejected Blog Post - claims it's off-topic. Creator says client brief was vague." She clicks into the dispute case. Everything is there: the original audio file (she can listen), the transcript, the client's initial brief, the creator's three submission attempts with timestamps, the QA editor's scores and inline comments, and the full message history.

Sarah listens to 2 minutes of the audio, reads the brief, and sees the pattern immediately: the client's brief said "focus on practical applications" but the audio spent 80% on theory. The creator followed the audio accurately. The QA editor approved it (4.2/5) because accuracy was technically correct. This isn't a quality issue - it's a client expectation mismatch. She uses the decision support tool: "Partial Refund (50%) - Client Brief Mismatch." She drafts messages to both parties explaining the decision with evidence timestamps. Total time: 8 minutes instead of the usual 45.

Six months later, Sarah has processed 180 disputes with an average resolution time of 12 minutes. Her decisions are consistent because she has all the context, refund rate has dropped from 8% to 3% because she can educate clients on better briefs, and creator satisfaction is up because they know disputes will be fair. She's shifted 70% of her time from firefighting to strategy: analyzing quality trends, identifying creators for advancement, and planning the enterprise tier rollout. When asked about the change, she says: "I finally feel like I'm managing a marketplace, not just managing chaos."

## Journey Requirements Summary

These four narrative journeys reveal the following capability requirements across the platform:

**Upload & Content Delivery Capabilities (Alex's Journey):**
- Simple, intuitive upload interface with multi-format selection
- Clear turnaround time expectations and progress visibility
- Quality notification system for delivery alerts
- Download interface supporting multiple format options (MD, PDF, DOCX)
- Rush/express pricing tiers for ROI-conscious power users
- Repeat order workflow optimization

**Creator Workspace & Advancement (Maria's Journey):**
- Fair, transparent creator application and vetting process
- Task board interface with clear value visibility (creator payout shown, client pricing hidden)
- Advanced audio player with synchronized transcript and variable speed playback
- Rich text block-based editor with auto-save functionality
- Real-time tier progression tracking and advancement notifications
- Weekly payout system with transparent earnings dashboard
- Actionable, specific QA feedback (not vague critiques)
- Task claiming and locking mechanism to prevent double-assignment

**QA Review & Quality Management (James's Journey):**
- Scalable review queue with flexible sorting (deadline, creator, content type)
- Side-by-side review interface (audio + transcript + submission in one view)
- Structured rubric-based scoring system (6 dimensions with weighting)
- Inline commenting capability for specific feedback
- Performance analytics dashboard (first-pass rates, review velocity, quality trends)
- Multi-editor workflow support with consistent standards
- Creator performance tracking over time

**Admin Operations & Dispute Resolution (Sarah's Journey):**
- Comprehensive dispute context view aggregating all evidence
- Integrated audio playback with transcript access for verification
- Complete submission history with timestamps and version tracking
- Full message history integration across client-creator-QA communications
- Decision support tools with templated resolution options
- Analytics dashboard for operational insights (quality trends, refund rates, creator performance metrics)
- Refund processing workflow with reason tracking
- Client education tools for brief writing and expectation management

